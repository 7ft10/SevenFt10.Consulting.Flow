# Intro to Agile Testing

Agile testing overview

## Principles&#x20;

The following Testing principles have been designed to be in line with Industry best practices.

Each test case tests one thing - and only one thing.&#x20;

The overarching principles of testing at A\&G are to:

* Ensure testing is based on mitigating risks to the business
* Automate tests as a priority
* Demonstrate the software meets the Acceptance Criteria
* Verify that the solution meets the stated business and technical requirements
* Ensure that all defects/omissions outstanding at the end of the testing cycle are documented, and an action plan is in place for their resolution.
* Reduce the risk of software defects reaching production.

<table><thead><tr><th width="231">Principle</th><th>Description</th></tr></thead><tbody><tr><td>Testing shows the presence of defects, not their absence</td><td>Testing can show that defects are present, but cannot prove that there are no defects. Testing reduces the probability of undiscovered defects remaining in the software but, even if no defects are found, testing is not a proof of correctness.</td></tr><tr><td>Exhaustive testing is impossible</td><td>Testing everything (all combinations of inputs and preconditions) is not feasible except for trivial cases. Rather than attempting to test exhaustively, risk analysis, test techniques, and priorities should be used to focus test efforts.</td></tr><tr><td>Early testing saves time and money</td><td>To find defects early, both static and dynamic test activities should be started as early as possible in the software development lifecycle. Early testing is sometimes referred to as shift left. Testing early in the software development lifecycle helps reduce or eliminate costly changes.</td></tr><tr><td>Defects cluster together</td><td>A few modules usually contain most of the defects discovered during pre-release testing or are responsible for most of the operational failures. Predicted defect clusters, and the actually observed defect clusters in a test or operation, are important inputs into a risk analysis used to focus the test effort.</td></tr><tr><td>Beware of the pesticide paradox</td><td>If the same tests are repeated over and over again, eventually these tests no longer find any new defects. To detect new defects, existing tests and test data may need changing, and new tests may need to be written. (Tests are no longer effective at finding defects, just as pesticides are no longer effective at killing insects after a while.) In some cases, such as automated regression testing, the pesticide paradox has a beneficial outcome, which is the relatively low number of regression defects.</td></tr><tr><td>Testing is context dependent</td><td>Testing is done differently in different contexts. </td></tr><tr><td>Absence-of-errors is a fallacy</td><td>Some organizations expect that testers can run all possible tests and find all possible defects, but principles 2 and 1, respectively, tell us that this is impossible. Further, it is a fallacy (i.e., a mistaken belief) to expect that just finding and fixing a large number of defects will ensure the success of a system. For example, thoroughly testing all specified requirements and fixing all defects found could still produce a system that is difficult to use, that does not fulfill the users’ needs and expectations, or that is inferior compared to other competing systems.</td></tr><tr><td>Collaborative Approach</td><td>Where possible a Test-Driven Development approach will be taken. Unit tests will be written by the developers and run before publishing any new build candidates for deployment. Test Analysts will also be able to use the unit test framework to expand their API level tests.</td></tr><tr><td>Shared Responsibility</td><td><p>Testers are NOT the only group responsible for quality.  Quality is everyone’s responsibility. Developers should validate their own work to the best of their ability and strive to get better at doing so over time.</p><p>Quality begins at story writing/elaboration and building high quality acceptance criteria and flows right through the Software Delivery Life Cycle (SDLC) through to User Acceptance Testing. It involves all roles, including Product Owners, Business Analysts, Developers and Testers. Strong collaboration is the channel to high quality and the earlier quality issues are identified; the more cost effective it is to address them.</p></td></tr><tr><td>Define Quality Early</td><td>Quality must be defined early in the development lifecycle. This means that acceptance criteria, supporting test cases and definitions of done are defined in the earliest stages of the project life cycle to ensure everyone involved has a clear and common understanding of the level of quality that is acceptable and how, as a team, this will be achieved.</td></tr><tr><td>Create Fast Feedback Loops</td><td><p>A feedback loop in the context of application software development and change is the time it takes to verify or validate the deployed code to ensure it meets expectations and requirements and for this feedback to make its way back to the developer of the application software. This cycle is known as the Feedback Loop.</p><p>The longer the period of time between deploying the new or updated application code and receiving feedback as to its acceptability, the longer time the defect has had to propagate through the system, the more time it has had to create additional issues and the more expensive it becomes to correct the original defect and remediate the subsequent consequences.</p><p>The sooner feedback on a defect is passed back to the developer, the sooner they can correct the issue. Consequently, a key motivator of the Test Strategy is to speed up this feedback loop so that defects do not get time to propagate and cause subsequent and possibly expensive issues.</p><p>Test early, test often and test appropriately.</p></td></tr><tr><td>Automation Testing</td><td>Automate high value repetitive and manual testing activities and tasks as much as possible.</td></tr><tr><td>Tests are independent</td><td>Tests should be independent of other tests so they can be run in parallel to increase feedback. Tests should also be responsible for managing their own data, an ideal test creates its state and tears it down upon completion</td></tr><tr><td>Testers Test as Users Use</td><td>We should always aim to interact with the system under test in the same way that the user would. If a portion of your business logic is on the client side (e.g. browser) you must test through the UI for that functionality. Only if the application is service architected can you confidently test through the service layers to mimic that user interaction. UI tests should still be run to detect presentation layer defects.</td></tr><tr><td>Risk Based Testing</td><td>A risk-based approach will be used to determine test coverage. A risk-based testing approach brings formal risk assessment methods to the testing process to prioritize the tests for suitable coverage and allocate testing effort. Risk-based testing provides higher confidence that the right level and type of coverage on the right things at the right time to prevent probable issues that carry high impact and high cost given the introduced changes under test.</td></tr><tr><td>Data Management</td><td>Production data must be obfuscated before being used for testing in non-production environments. When testing in production environments the following guidelines must be followed. </td></tr><tr><td>Segregation of Duties</td><td>As an agile technology team, every delivery team member is expected to contribute to delivering their agreed work. However, to ensure quality, duties are expected to be segregated so that an author of a piece of work will never be the reviewer.</td></tr></tbody></table>

## Test Automation Principles

The following Test Automation principles have been designed to be in line with industry best practices.

<table><thead><tr><th width="225">Principle</th><th>Description</th></tr></thead><tbody><tr><td>Tests should be expressive</td><td>It should be transparent what is being tested by an automated test. Let's leave the guesswork out of this and make the tests expressive and transparent. This helps other Technical Testers, Functional Tests, Developers and stakeholders.</td></tr><tr><td>Tests should be independent</td><td>Tests should not depend on other tests for the state. Tightly coupled tests erode the value of building and running the tests as a continuous regression safety net due to intermittency issues caused by tests having to run in a certain sequence. Ideally, a test should also be responsible for its own (test) data. Meaning it prepares the test data required and cleans it up again.</td></tr><tr><td>Tests should be fast</td><td>Only when automated tests run fast, we can run them at any stage and as often as necessary or required. The aim here is to allow for fast feedback. Having to wait hours for automated tests to complete, defeats the purpose.<br>This also means keeping long running e2e tests to a minimum.</td></tr><tr><td>Tests should be repeatable</td><td>With no changes to a system under test, automated tests should produce the same results consistently. Tests that are not repeatable, or unstable, do not provide a lot of confidence.</td></tr><tr><td>Tests should be maintainable</td><td>Software products change and so will automated tests. Only a test that is easy to read and understand is easy to maintain. Simplicity is key. See <a href="https://en.wikipedia.org/wiki/KISS_principle">KISS Principle</a></td></tr><tr><td>Tests should be easy to run</td><td>If tests are hard to run, we discourage others to utilise them. Goal is to have tests that can be run anywhere at any time. Tests that are easy to run will allow for simpler pipelines as well.</td></tr><tr><td>Keep the lights on</td><td>Keep the tests maintained and efficient. This also applies to the framework itself by reducing tech debt and keeping it and its dependencies up to date.<br>Having healthy pipelines is part of this as well. Pipelines that look like a Christmas tree (red / green) don't build confidence.</td></tr><tr><td>Don't repeat yourself</td><td>This principle can be applied to two areas - code and tests. Don't duplicate code to keep it easier to read and maintain, and don't duplicate test coverage. Something that has been verified by one test, doesn't need to be tested again.</td></tr><tr><td>No shortcuts</td><td>Manual testing is no shortcut if automated tests are broken or don't work. Invest the time to keep the test maintained and healthy.<br>Also, don't run the tests locally if there are (and there should be) pipelines for those tests. If the pipelines take too long to complete, look at optimising them.</td></tr></tbody></table>

## 4 Aces Model

An extension to the AAA pattern of testing that looks beyond the original intended unit testing methods. The additional A stands for "Annihilate", which is the important clean-up step after tests have been run to allow them to be run over and over.&#x20;

<figure><img src="../../.gitbook/assets/image (26).png" alt="" width="375"><figcaption></figcaption></figure>

For unit tests, this is simple, meaning that any potential disk writing or state change actions are mocked out or only affected within a short-lived memory space. But, for tests higher up in the test triangle, this may mean that transactions can be reversed or not committed or that the entire environment can be replaced (through methods like IAC).&#x20;

### ♦ Arrange

Crystalise the environment into the perfect state.

### ♠ Act

Dig in and do the work.

### ♥ Assert

Love the outcomes - and find the heartbreakers.

### ♣ Annihilate

Club the environment back to what is was like before the test was run.
